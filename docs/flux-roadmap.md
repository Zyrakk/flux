# Flux â€” Roadmap Completo de ImplementaciÃ³n

## VisiÃ³n del Proyecto

**Flux** es una plataforma self-hosted de inteligencia informativa que transforma cientos de fuentes diarias en un briefing matutino personalizado. Construido en Go, desplegado en k3s (o Docker Compose), alimentado por LLM vÃ­a interfaz abstracta (GLM, OpenAI-compatible, Anthropic).

**Principio core:** Leer menos, leer mejor. El sistema hace el scroll por ti.

> ğŸ“„ **Documento complementario: `flux-source-catalog.md`** â€” CatÃ¡logo completo de fuentes RSS, subreddits, y AI labs organizados por secciÃ³n, con URLs, descripciones, y valoraciones seÃ±al/ruido.

---

## Decisiones ArquitectÃ³nicas Fundamentales

### Stack TecnolÃ³gico

| Componente | TecnologÃ­a | JustificaciÃ³n |
|---|---|---|
| Backend / Workers | Go | Rendimiento, concurrencia nativa, ecosistema cloud-native |
| Base de datos relacional | PostgreSQL 16 + pgvector | Una sola DB para datos + embeddings, operacionalmente simple |
| Cola de mensajes | NATS JetStream | Ligero, cloud-native, Go-nativo, perfecto para k3s |
| Cache | Redis (Valkey) | DeduplicaciÃ³n rÃ¡pida, rate limiting, estado efÃ­mero |
| Frontend | Svelte/SvelteKit | Ligero, rÃ¡pido, SSR nativo, ideal para dashboard |
| LLM | Interfaz abstracta (GLM-4.7 por defecto) | Soporta GLM, OpenAI-compatible (Ollama, vLLM), Anthropic |
| Embeddings | all-MiniLM-L6-v2 (local) | Gratuito, ~80MB, corre en CPU sin problema |
| Ingress | Traefik (incluido en k3s) | Ya disponible en tu cluster |
| Almacenamiento | PVC en el DAS de 24TB (Pi 5) | Archivo histÃ³rico masivo |

### Principio de Modularidad

Cada componente es un **microservicio independiente** con su propio Deployment en k3s. Se comunican exclusivamente vÃ­a NATS (eventos asÃ­ncronos) y PostgreSQL (estado compartido). Si el worker de Reddit se rompe, el de HN sigue funcionando. Si GLM estÃ¡ caÃ­do, los artÃ­culos se encolan y se procesan cuando vuelva. Nada es sÃ­ncrono salvo la UI leyendo de la DB.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        INGRESS (Traefik)                    â”‚
â”‚                     flux.zyrak.cloud                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                              â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
       â”‚   Frontend    â”‚              â”‚   API Server   â”‚
       â”‚   (Svelte)    â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚   (Go)         â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                         â”‚                      â”‚
             â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
             â”‚ PostgreSQL  â”‚          â”‚     NATS      â”‚     â”‚    Redis     â”‚
             â”‚ + pgvector  â”‚          â”‚  JetStream    â”‚     â”‚  (Valkey)    â”‚
             â””â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                         â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚           â”‚           â”‚             â”‚            â”‚
   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
   â”‚ Worker â”‚ â”‚ Worker â”‚ â”‚ Worker â”‚  â”‚ Worker  â”‚  â”‚  Processor  â”‚
   â”‚  RSS   â”‚ â”‚   HN   â”‚ â”‚ Reddit â”‚  â”‚ GitHub  â”‚  â”‚  (GLM +     â”‚
   â”‚        â”‚ â”‚        â”‚ â”‚        â”‚  â”‚Releases â”‚  â”‚  Embeddings)â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### AbstracciÃ³n del LLM (CrÃ­tico para Open Source)

El backend LLM se abstrae desde el dÃ­a 1 mediante una interface Go en `internal/llm/`:

```go
type Analyzer interface {
    Classify(ctx context.Context, articles []Article) ([]Classification, error)
    Summarize(ctx context.Context, article Article) (string, error)
    GenerateBriefing(ctx context.Context, articles []SummarizedArticle) (string, error)
}
```

Implementaciones:
- `glm.go` â€” GLM-4.7 vÃ­a API (tu configuraciÃ³n por defecto con plan Coding Lite)
- `openai_compat.go` â€” Cualquier API compatible con OpenAI (Ollama, vLLM, LiteLLM, Together, Groq)
- `anthropic.go` â€” API de Anthropic (Claude)

El usuario elige el backend en el `values.yaml` / `docker-compose.yml` / variables de entorno:
```yaml
llm:
  provider: "glm"           # glm | openai_compat | anthropic
  endpoint: "https://open.bigmodel.cn/api/paas/v4"
  model: "glm-4.7"
  apiKey: "<secret>"
```

Esto te protege a ti (si GLM cambia el plan, migras en 5 minutos) y hace el proyecto usable para cualquiera que tenga un Ollama local o una API key de OpenAI.

### Despliegue Dual: Helm + Docker Compose

El proyecto ofrece dos modos de despliegue:

- **Helm chart** (para k3s/Kubernetes): Tu modo principal, con todas las ventajas de k8s (CronJobs nativos, health checks, rolling updates, nodeSelectors para el cluster hÃ­brido).
- **Docker Compose** (para la mayorÃ­a de la comunidad self-hosted): Un `docker-compose.yml` en la raÃ­z del repo que levanta todo con un solo `docker compose up -d`. Mismo stack (PostgreSQL, NATS, Redis, workers, API, frontend), sin necesitar Kubernetes.

Ambos comparten las mismas imÃ¡genes Docker. La diferencia es solo orquestaciÃ³n. El Docker Compose se mantiene desde la fase 0 en paralelo al Helm chart â€” no es un "port" tardÃ­o, sino un ciudadano de primera clase.

### Rate Limiting Global de Ingesta

Todos los workers comparten un rate limiter centralizado en Redis para evitar baneos:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Worker RSS   â”‚â”€â”€â”€â”€â–ºâ”‚           â”‚     â”‚ Fuente externa   â”‚
â”‚ Worker HN    â”‚â”€â”€â”€â”€â–ºâ”‚   Redis   â”‚â”€â”€â”€â”€â–ºâ”‚ (Reddit, HN,     â”‚
â”‚ Worker Redditâ”‚â”€â”€â”€â”€â–ºâ”‚  Limiter  â”‚     â”‚  blogs, APIs)    â”‚
â”‚ Worker GitHubâ”‚â”€â”€â”€â”€â–ºâ”‚           â”‚     â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

ConfiguraciÃ³n por fuente en `internal/ratelimit/`:
- **HN API**: 30 req/min (generosa, pero no abusar)
- **Reddit API**: 60 req/min (lÃ­mite oficial con OAuth)
- **RSS fetch**: 10 req/min global (descarga de artÃ­culos completos con `go-readability`)
- **GitHub API**: 5000 req/h (con token personal)
- **NVD API**: 50 req/30s (con API key)

AdemÃ¡s, para la descarga de contenido completo de artÃ­culos (`go-readability`):
- Delay aleatorio de 1-3s entre requests al mismo dominio
- Respeto de `robots.txt` y `Retry-After` headers
- User-Agent identificativo (`Flux/1.0 +https://github.com/zyrak/flux`)
- Si un dominio devuelve 429 o 403, backoff exponencial y se marca en Redis para no reintentar en 1h

### Estrategia de Coste con GLM

El plan Coding Lite renueva el cap cada 5 horas. La estrategia:

- **CronJob a las 03:00**: Dispara el pipeline de procesamiento.
- **Fase 1 â€” Filtrado barato (embeddings locales)**: Calcula similaridad coseno contra el perfil del usuario. Descarta ~80% de artÃ­culos. Coste GLM: 0.
- **Fase 2 â€” ClasificaciÃ³n con GLM**: Solo los ~20% supervivientes pasan por GLM para clasificaciÃ³n y descarte de clickbait. Coste: bajo.
- **Fase 3 â€” SÃ­ntesis con GLM**: Los ~10-15 artÃ­culos finales se sintetizan en el briefing. Coste: moderado.
- **Resultado**: A las 07:00â€“08:00 el briefing estÃ¡ listo y el cap de GLM se ha renovado o estÃ¡ a punto.

---

## Fuentes de Ingesta

> ğŸ“„ **El catÃ¡logo completo de fuentes estÃ¡ en `flux-source-catalog.md`**, con URLs de feeds, descripciÃ³n de cada fuente, valoraciÃ³n seÃ±al/ruido, y subreddits por secciÃ³n.

### Resumen por SecciÃ³n

| SecciÃ³n | Feeds RSS | Subreddits | ArtÃ­culos/dÃ­a (pre-filtro) | En briefing |
|---|---|---|---|---|
| ğŸ”’ Cybersecurity | 12 (tl;dr sec, Krebs, THN, BleepingComputer, Schneier, SANS ISC, Troy Hunt, Miessler, Risky Business, TLDR InfoSec, Dark Reading, Red Hat Security) | 4 (r/netsec, r/cybersecurity, r/AskNetsec, r/blueteamsec) | ~80-120 | 5 |
| ğŸ’» Tech | 14 + 10 AI labs (TLDR, Ars, Lobsters, LWN, Go Blog, K8s Blog, OpenShift Blog, stderr.at, OKD, Papers We Love, Ollama, The Verge + Anthropic, OpenAI, xAI, DeepMind, GLM, Kimi feeds) | 8 (r/kubernetes, r/selfhosted, r/homelab, r/LocalLLaMA, r/MachineLearning, r/golang, r/linux, r/openshift) | ~150-250 | 5 |
| ğŸ“ˆ Economy | 9 (Bloomberg Tech, Reuters Business, CNBC Tech, CoinDesk, The Block, Finimize, FT Tech, TLDR Founders, ExpansiÃ³n) | 6 (r/stocks, r/wallstreetbets, r/CryptoCurrency, r/investing, r/economics, r/nvidia) | ~100-180 | 3 |
| ğŸŒ World | 6 (Reuters Top, BBC World, AP News, El PaÃ­s, The Guardian, Al Jazeera) | 3 (r/worldnews, r/geopolitics, r/europe) | ~80-150 | 2 |
| **Total** | **~51** | **~21** | **~400-700** | **~15** |

### Fuentes Multi-SecciÃ³n

Hacker News, Reuters, y Ars Technica generan contenido que cruza secciones. No se asignan a una secciÃ³n fija â€” el motor de embeddings clasifica cada artÃ­culo en la secciÃ³n mÃ¡s relevante automÃ¡ticamente.

### Prioridad de ImplementaciÃ³n

- **Fase 1 (MVP)**: RSS de todas las secciones + HN API
- **Fase 4**: Reddit API (21 subreddits) + GitHub Releases + AI labs sin RSS (GLM, Kimi vÃ­a GitHub API)
- **Fase posterior**: Bluesky, Mastodon, ArXiv, YouTube transcripts

---

## FASE 0 â€” Scaffolding y Fundamentos
**DuraciÃ³n estimada: 1.5 semanas**
**Objetivo: Tener el esqueleto del proyecto, CI, infraestructura base desplegada en k3s Y Docker Compose, interfaz LLM abstracta, y rate limiter listo.**

### Tareas

#### 0.1 â€” Estructura del repositorio
```
flux/
â”œâ”€â”€ cmd/
â”‚   â”œâ”€â”€ api/              # Servidor API HTTP
â”‚   â”œâ”€â”€ worker-rss/       # Worker de ingesta RSS
â”‚   â”œâ”€â”€ worker-hn/        # Worker de ingesta HN
â”‚   â”œâ”€â”€ worker-reddit/    # Worker de ingesta Reddit
â”‚   â”œâ”€â”€ processor/        # Pipeline de procesamiento (embeddings + GLM)
â”‚   â””â”€â”€ briefing-gen/     # Generador de briefings (CronJob)
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ models/           # Structs compartidos (Article, Briefing, Feedback)
â”‚   â”œâ”€â”€ store/            # Capa de acceso a PostgreSQL
â”‚   â”œâ”€â”€ queue/            # AbstracciÃ³n sobre NATS
â”‚   â”œâ”€â”€ embeddings/       # Cliente para modelo de embeddings local
â”‚   â”œâ”€â”€ llm/              # Interfaz abstracta + implementaciones (GLM, OpenAI-compat, Anthropic)
â”‚   â”œâ”€â”€ dedup/            # LÃ³gica de deduplicaciÃ³n (Redis + hashing)
â”‚   â””â”€â”€ ratelimit/        # Rate limiter centralizado por fuente (Redis-backed)
â”œâ”€â”€ web/                  # Frontend Svelte
â”œâ”€â”€ deploy/
â”‚   â”œâ”€â”€ helm/
â”‚   â”‚   â””â”€â”€ flux/        # Helm chart principal
â”‚   â””â”€â”€ docker/           # Dockerfiles por servicio
â”œâ”€â”€ docker-compose.yml    # Despliegue alternativo sin Kubernetes
â”œâ”€â”€ migrations/           # Migraciones SQL (golang-migrate)
â”œâ”€â”€ scripts/              # Scripts de utilidad
â”œâ”€â”€ go.mod
â”œâ”€â”€ go.sum
â”œâ”€â”€ Makefile
â””â”€â”€ README.md
```

#### 0.2 â€” Helm Chart base
- Namespace dedicado: `flux`
- PostgreSQL (Bitnami chart como dependencia o tu propia instancia existente)
- NATS (chart oficial)
- Redis/Valkey (chart Bitnami)
- ConfigMap para configuraciÃ³n compartida (lista de feeds, subreddits, etc.)
- Secrets para credenciales (API key GLM, Reddit OAuth, etc.)
- IngressRoute de Traefik con TLS

#### 0.3 â€” Base de datos â€” Schema inicial
```sql
-- Secciones del briefing (modulares, activables/desactivables)
CREATE TABLE sections (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name TEXT NOT NULL UNIQUE,        -- 'cybersecurity', 'tech', 'economy', 'world'
    display_name TEXT NOT NULL,       -- 'ğŸ”’ Cybersecurity'
    enabled BOOLEAN DEFAULT TRUE,
    sort_order INTEGER DEFAULT 0,
    max_briefing_articles INTEGER DEFAULT 5,
    seed_keywords TEXT[],             -- Para cold start del perfil por secciÃ³n
    config JSONB                      -- ConfiguraciÃ³n extra
);

-- ArtÃ­culos ingestados
CREATE TABLE articles (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    source_type TEXT NOT NULL,        -- 'rss', 'hn', 'reddit', 'github'
    source_id TEXT NOT NULL,          -- ID Ãºnico en la fuente original
    section_id UUID REFERENCES sections(id), -- SecciÃ³n asignada por el motor de relevancia
    url TEXT NOT NULL,
    title TEXT NOT NULL,
    content TEXT,                     -- Texto completo del artÃ­culo
    summary TEXT,                     -- TL;DR generado por LLM
    author TEXT,
    published_at TIMESTAMPTZ,
    ingested_at TIMESTAMPTZ DEFAULT NOW(),
    processed_at TIMESTAMPTZ,        -- CuÃ¡ndo lo procesÃ³ el LLM
    embedding vector(384),           -- all-MiniLM-L6-v2 output
    relevance_score FLOAT,           -- Score calculado vs perfil de la secciÃ³n asignada
    categories TEXT[],               -- Tags asignados por LLM
    status TEXT DEFAULT 'pending',   -- pending, processed, briefed, archived
    metadata JSONB,                  -- Datos extra segÃºn fuente (HN score, Reddit upvotes...)
    UNIQUE(source_type, source_id)
);

-- Ãndices
CREATE INDEX idx_articles_status ON articles(status);
CREATE INDEX idx_articles_published ON articles(published_at DESC);
CREATE INDEX idx_articles_section ON articles(section_id);
CREATE INDEX idx_articles_embedding ON articles USING ivfflat (embedding vector_cosine_ops);

-- Briefings generados
CREATE TABLE briefings (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    generated_at TIMESTAMPTZ DEFAULT NOW(),
    content TEXT NOT NULL,            -- Briefing completo en Markdown (con secciones)
    article_ids UUID[],              -- ArtÃ­culos incluidos
    metadata JSONB                   -- Stats por secciÃ³n: artÃ­culos procesados, descartados, etc.
);

-- Feedback del usuario (vinculado a secciÃ³n vÃ­a artÃ­culo)
CREATE TABLE feedback (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    article_id UUID REFERENCES articles(id),
    action TEXT NOT NULL,             -- 'like', 'dislike', 'save', 'follow_topic'
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Perfil de intereses POR SECCIÃ“N (cada secciÃ³n evoluciona independientemente)
CREATE TABLE section_profiles (
    section_id UUID REFERENCES sections(id),
    positive_embedding vector(384),    -- Centroide de likes en esta secciÃ³n
    negative_embedding vector(384),    -- Centroide de dislikes en esta secciÃ³n
    like_count INTEGER DEFAULT 0,
    dislike_count INTEGER DEFAULT 0,
    updated_at TIMESTAMPTZ DEFAULT NOW(),
    PRIMARY KEY (section_id)
);

-- Fuentes configuradas
CREATE TABLE sources (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    source_type TEXT NOT NULL,
    name TEXT NOT NULL,
    config JSONB NOT NULL,            -- URL del feed, subreddit name, etc.
    enabled BOOLEAN DEFAULT TRUE,
    last_fetched_at TIMESTAMPTZ,
    error_count INTEGER DEFAULT 0,
    last_error TEXT
);

-- RelaciÃ³n fuentes â†” secciones (muchos a muchos)
-- Una fuente puede alimentar mÃºltiples secciones (ej: Reuters â†’ Economy + World)
CREATE TABLE source_sections (
    source_id UUID REFERENCES sources(id),
    section_id UUID REFERENCES sections(id),
    PRIMARY KEY (source_id, section_id)
);

-- Seed data: secciones iniciales
INSERT INTO sections (name, display_name, sort_order, max_briefing_articles, seed_keywords) VALUES
('cybersecurity', 'ğŸ”’ Cybersecurity', 1, 5, ARRAY['CVE vulnerability exploit', 'ransomware malware threat', 'kubernetes security RBAC', 'zero-day attack', 'data breach incident']),
('tech', 'ğŸ’» Tech', 2, 5, ARRAY['kubernetes container orchestration', 'golang Go programming', 'LLM AI model release', 'self-hosted open source', 'linux kernel development']),
('economy', 'ğŸ“ˆ Economy', 3, 3, ARRAY['NVIDIA stock earnings semiconductor', 'Bitcoin cryptocurrency market', 'tech stock earnings revenue', 'Federal Reserve interest rates']),
('world', 'ğŸŒ World', 4, 2, ARRAY['geopolitical conflict major event', 'climate disaster emergency', 'election government change', 'international treaty sanctions']);
```

#### 0.4 â€” CI bÃ¡sico
- GitHub Actions: lint (`golangci-lint`), test, build de imÃ¡genes Docker
- Multi-arch builds (amd64 + arm64) â€” necesario para tu cluster hÃ­brido
- Push a un registry (GitHub Container Registry o tu propio Harbor si tienes)

#### 0.5 â€” Dockerfiles multi-stage
Un Dockerfile por binario en `deploy/docker/`, todos con el mismo patrÃ³n:
```dockerfile
FROM golang:1.23-alpine AS builder
# ... build ...
FROM alpine:3.20
# ... binary + ca-certificates + tzdata
```

#### 0.6 â€” Interfaz abstracta de LLM
Implementar la interface `Analyzer` en `internal/llm/` con las tres implementaciones desde el inicio:
- `glm.go` â€” tu backend por defecto (GLM-4.7 vÃ­a plan Coding Lite)
- `openai_compat.go` â€” cualquier API compatible con OpenAI (Ollama, vLLM, LiteLLM, Together, Groq, etc.)
- `anthropic.go` â€” API de Claude
- `factory.go` â€” factory que instancia la implementaciÃ³n correcta segÃºn configuraciÃ³n

SelecciÃ³n por variable de entorno o config:
```yaml
# En values.yaml / docker-compose.yml / .env
LLM_PROVIDER=glm              # glm | openai_compat | anthropic
LLM_ENDPOINT=https://open.bigmodel.cn/api/paas/v4
LLM_MODEL=glm-4.7
LLM_API_KEY=<secret>
```

Esto es fundacional â€” hacerlo despuÃ©s requiere refactorizar todo el procesamiento. Hacerlo ahora son 2-3 horas extra y evita meses de dolor.

#### 0.7 â€” Docker Compose base
`docker-compose.yml` en la raÃ­z del repo como ciudadano de primera clase:
```yaml
services:
  postgres:
    image: pgvector/pgvector:pg16
  nats:
    image: nats:2-alpine
    command: ["--jetstream"]
  redis:
    image: valkey/valkey:8-alpine
  api:
    build: { context: ., dockerfile: deploy/docker/Dockerfile.api }
    depends_on: [postgres, nats, redis]
  worker-rss:
    build: { context: ., dockerfile: deploy/docker/Dockerfile.worker-rss }
    depends_on: [postgres, nats, redis]
  worker-hn:
    build: { context: ., dockerfile: deploy/docker/Dockerfile.worker-hn }
    depends_on: [postgres, nats, redis]
  frontend:
    build: { context: ., dockerfile: deploy/docker/Dockerfile.frontend }
    ports: ["8080:8080"]
```

Se mantiene en paralelo al Helm chart. Cada vez que se aÃ±ade un servicio al Helm chart, se aÃ±ade al Compose. No es un "port" tardÃ­o.

#### 0.8 â€” Rate Limiter centralizado
Implementar `internal/ratelimit/` con un rate limiter Redis-backed configurable por dominio/fuente:
- PatrÃ³n token bucket con Redis (`EVALSHA` de script Lua para atomicidad)
- ConfiguraciÃ³n por fuente: `{"reddit.com": "60/min", "hn.algolia.com": "30/min", "default": "10/min"}`
- Respeto automÃ¡tico de `Retry-After` headers
- Backoff exponencial por dominio tras 429/403
- Delay aleatorio (1-3s jitter) entre requests al mismo dominio para descarga de contenido
- User-Agent identificativo: `Flux/1.0 (+https://github.com/zyrak/flux)`
- Todos los workers importan este paquete â€” ningÃºn worker hace requests directos sin pasar por el limiter

### Criterio de Fase Completada
- `helm install flux ./deploy/helm/flux` levanta PostgreSQL, NATS, Redis en tu cluster
- `docker compose up -d` levanta lo mismo en cualquier mÃ¡quina con Docker
- Las tablas se crean automÃ¡ticamente (Job de migraciÃ³n)
- El IngressRoute responde en `flux.zyrak.cloud` (aunque solo sea un 200 OK)
- `internal/llm/` compila y tiene tests unitarios para las tres implementaciones (al menos con mocks)
- `internal/ratelimit/` compila y tiene tests que verifican el throttling

---

## FASE 1 â€” Ingesta BÃ¡sica (RSS + Hacker News)
**DuraciÃ³n estimada: 1.5â€“2 semanas**
**Objetivo: ArtÃ­culos de RSS y HN fluyendo a la base de datos, deduplicados.**

### Tareas

#### 1.1 â€” Worker RSS
- Parser RSS/Atom usando `gofeed` (librerÃ­a Go madura)
- Lee la lista de feeds desde la tabla `sources`
- Para cada artÃ­culo nuevo:
  - Calcula hash SHA-256 de URL normalizada
  - Check en Redis (`SETNX`) para dedup rÃ¡pido
  - Si es nuevo, publica evento en NATS `articles.new`
  - Inserta en PostgreSQL con status `pending`
- Descarga contenido completo del artÃ­culo con `go-readability` (extrae texto limpio del HTML)
- **Todas las requests HTTP pasan por `internal/ratelimit/`** â€” respeta los lÃ­mites por dominio, jitter entre requests, y backoff automÃ¡tico ante 429/403
- **Resiliencia**: si un feed falla, incrementa `error_count` en `sources`, aplica backoff exponencial, continÃºa con el siguiente feed. Un feed roto no afecta a los demÃ¡s.
- CronJob en k3s: cada 30 minutos

#### 1.2 â€” Worker Hacker News
- Usa la API oficial de Firebase de HN (`https://hacker-news.firebaseio.com/v0/`)
- Endpoints: `topstories`, `beststories`, `newstories`
- Para cada story con score > 10 (configurable):
  - Obtiene tÃ­tulo, URL, score, comentarios
  - Si tiene URL externa, descarga contenido con `go-readability`
  - Si es un "Ask HN" o "Show HN" sin URL, guarda el texto del post
  - Dedup por URL contra Redis + PostgreSQL
  - Publica en NATS `articles.new`
- Guarda metadata HN en el campo JSONB: `{"hn_score": 142, "hn_comments": 87, "hn_id": 12345}`
- CronJob: cada 15 minutos (la API de HN es generosa y sin auth, pero el rate limiter controla igualmente)

#### 1.3 â€” Servicio de DeduplicaciÃ³n
- No es un servicio separado, es una librerÃ­a compartida en `internal/dedup/`
- **Nivel 1**: Hash de URL normalizada (quitar tracking params, normalizar www)
- **Nivel 2**: DetecciÃ³n de "misma historia, diferente URL" â€” esto se harÃ¡ en Fase 3 con embeddings. Por ahora, solo URL.
- Redis set con TTL de 7 dÃ­as para dedup rÃ¡pido
- PostgreSQL UNIQUE constraint como backup definitivo

#### 1.4 â€” API Server (endpoints bÃ¡sicos)
- `GET /api/articles` â€” Lista artÃ­culos (paginado, filtrable por source, status, fecha)
- `GET /api/articles/:id` â€” Detalle de un artÃ­culo
- `GET /api/sources` â€” Lista de fuentes configuradas
- `POST /api/sources` â€” AÃ±adir nueva fuente
- `PATCH /api/sources/:id` â€” Habilitar/deshabilitar fuente
- Health check: `GET /healthz`
- Framework: `net/http` estÃ¡ndar + `chi` router (ligero, idiomÃ¡tico)

### Criterio de Fase Completada
- Ejecutar manualmente los workers â†’ artÃ­culos aparecen en PostgreSQL
- `curl /api/articles` devuelve artÃ­culos reales de HN y tus feeds RSS
- Los workers corren como CronJobs en k3s sin intervenciÃ³n
- Si un feed RSS estÃ¡ caÃ­do, los demÃ¡s siguen funcionando
- Si el worker de HN falla, el de RSS no se entera

---

## FASE 2 â€” Procesamiento Inteligente (Embeddings + GLM)
**DuraciÃ³n estimada: 2 semanas**
**Objetivo: Los artÃ­culos se filtran por relevancia y GLM genera resÃºmenes.**

### Tareas

#### 2.1 â€” Servicio de Embeddings Local
- Modelo: `all-MiniLM-L6-v2` (384 dimensiones, ~80MB)
- OpciÃ³n A: Ejecutar con `onnxruntime` en Go (rendimiento nativo)
- OpciÃ³n B: Microservicio Python ultra-ligero con `sentence-transformers` + FastAPI (mÃ¡s simple de implementar, ~200MB de imagen Docker)
- **RecomendaciÃ³n: OpciÃ³n B para empezar**, migrar a Go puro si el rendimiento importa
- El servicio escucha eventos NATS `articles.new`, calcula embedding, actualiza la columna `embedding` en PostgreSQL
- Deployment: 1 rÃ©plica, resources limitados (256MB RAM, 0.5 CPU)

#### 2.2 â€” Motor de Relevancia (Scoring por SecciÃ³n)
- Al tener el embedding de un artÃ­culo:
  - **Paso 1 â€” AsignaciÃ³n de secciÃ³n**: Calcula similaridad coseno del artÃ­culo contra los `seed_keywords` embeddings de cada secciÃ³n activa. Asigna a la secciÃ³n con mayor score. Si la fuente pertenece a una sola secciÃ³n (`source_sections`), asignaciÃ³n directa sin cÃ¡lculo.
  - **Paso 2 â€” Scoring dentro de la secciÃ³n**: Contra el `section_profiles` de esa secciÃ³n:
    - `positive_score`: similaridad coseno contra `section_profiles.positive_embedding`
    - `negative_score`: similaridad coseno contra `section_profiles.negative_embedding`
    - `relevance_score = positive_score - (negative_score * 0.5) + source_boost`
    - `source_boost`: bonus configurable por fuente (ej: tl;dr sec = +0.1, Reddit genÃ©rico = 0)
- **Perfil inicial (cold start)**: Cada secciÃ³n se inicializa con embeddings de sus `seed_keywords` definidos en la tabla `sections`. Cybersecurity arranca con "CVE vulnerability", Tech con "kubernetes golang", Economy con "NVIDIA stock crypto", etc. Esto da un filtrado decente desde el dÃ­a 1 en las 4 secciones.
- ArtÃ­culos con `relevance_score < threshold` se marcan como `archived` directamente (no pasan por LLM, ahorro de tokens)
- El threshold es **por secciÃ³n** y se ajusta segÃºn volumen: si quedan >50 artÃ­culos en una secciÃ³n, sube; si quedan <5, baja

#### 2.3 â€” Pipeline LLM (vÃ­a interfaz abstracta)
- Usa `internal/llm.Analyzer` â€” tu configuraciÃ³n por defecto apunta a GLM-4.7, pero cualquier backend funciona
- **CronJob diario a las 03:00**
- Recoge todos los artÃ­culos con status `pending` + `relevance_score >= threshold`
- **Paso 1 â€” ClasificaciÃ³n** (un solo prompt con batch de tÃ­tulos + primeros pÃ¡rrafos):
  ```
  Clasifica estos artÃ­culos. Para cada uno, responde con:
  - relevant: true/false
  - section: una de [cybersecurity, tech, economy, world] (confirma o corrige la secciÃ³n asignada)
  - clickbait: true/false
  - reason: una frase explicando por quÃ© es o no relevante

  ArtÃ­culos:
  1. [tÃ­tulo] - [secciÃ³n pre-asignada] - [primer pÃ¡rrafo truncado a 200 chars]
  2. ...
  ```
- **Paso 2 â€” Resumen** (solo para artÃ­culos marcados como `relevant: true`):
  ```
  Resume este artÃ­culo en 2-3 frases. Si es una vulnerabilidad, incluye severidad
  y si hay parche. Si es cÃ³digo/herramienta, explica quÃ© hace y por quÃ© importa.
  Si hay datos concretos (benchmarks, cifras), inclÃºyelos.
  Si es una noticia financiera, incluye cifras clave y tendencia.

  [contenido completo del artÃ­culo]
  ```
- **Paso 3 â€” SÃ­ntesis del briefing por secciones** (prompt final):
  ```
  Genera un briefing matutino organizado en las siguientes secciones.
  Para cada secciÃ³n, destaca el artÃ­culo mÃ¡s importante primero.
  Si hay artÃ­culos relacionados entre secciones, conÃ©ctalos explÃ­citamente.
  Formato: Markdown. Tono: directo, tÃ©cnico, sin relleno.

  ## ğŸ”’ Cybersecurity (mÃ¡x 5 artÃ­culos)
  [artÃ­culos de cybersecurity con sus resÃºmenes]

  ## ğŸ’» Tech (mÃ¡x 5 artÃ­culos)
  [artÃ­culos de tech con sus resÃºmenes]

  ## ğŸ“ˆ Economy (mÃ¡x 3 artÃ­culos)
  [artÃ­culos de economy con sus resÃºmenes]

  ## ğŸŒ World (mÃ¡x 2 artÃ­culos)
  [artÃ­culos de world con sus resÃºmenes]
  ```
- El briefing generado se guarda en la tabla `briefings`
- Todos los artÃ­culos procesados se marcan como `processed` o `briefed`

#### 2.4 â€” GestiÃ³n de Errores con GLM
- Si GLM estÃ¡ caÃ­do o el rate limit estÃ¡ agotado:
  - Los artÃ­culos se quedan en `pending`
  - Se reintenta en el siguiente ciclo de 5h
  - El briefing se genera con lo que haya disponible
  - La UI muestra "Briefing parcial â€” X artÃ­culos pendientes de procesamiento"
- Timeouts generosos (120s por request) â€” GLM puede ser lento en batch
- Logging detallado de tokens consumidos por briefing para monitorizar uso

### Criterio de Fase Completada
- Los artÃ­culos tienen embeddings y relevance_score calculados
- El CronJob de las 03:00 genera un briefing real en Markdown
- Puedes leer el briefing en `GET /api/briefings/latest`
- Si GLM falla, el sistema no se rompe â€” los artÃ­culos esperan

---

## FASE 3 â€” Frontend y Experiencia de Usuario
**DuraciÃ³n estimada: 2 semanas**
**Objetivo: Web UI funcional donde lees el briefing, exploras artÃ­culos, y das feedback.**

### Tareas

#### 3.1 â€” UI del Briefing Matutino (PÃ¡gina principal)
- Dashboard que muestra:
  - **Briefing del dÃ­a organizado por secciones** (tabs o acordeones: ğŸ”’ Cyber | ğŸ’» Tech | ğŸ“ˆ Economy | ğŸŒ World)
  - **EstadÃ­sticas por secciÃ³n**: "Cyber: 87 procesados â†’ 5 en briefing | Tech: 192 â†’ 5 | Economy: 134 â†’ 3 | World: 95 â†’ 2"
  - **Hora de generaciÃ³n** y estado ("Completo" / "Parcial â€” 5 artÃ­culos pendientes")
- Cada artÃ­culo mencionado en el briefing tiene:
  - Enlace al original
  - Botones de **ğŸ‘ Like / ğŸ‘ Dislike** (el feedback se vincula a la secciÃ³n del artÃ­culo automÃ¡ticamente)
  - BotÃ³n de **ğŸ”– Guardar**
  - Badge de secciÃ³n con color
  - Fuente de origen (HN, RSS, Reddit) con icono

#### 3.2 â€” Feed de ArtÃ­culos
- PÃ¡gina secundaria: lista cronolÃ³gica de todos los artÃ­culos ingestados
- Filtros: por secciÃ³n, fuente, rango de fechas, solo "liked"
- Cada artÃ­culo muestra: tÃ­tulo, fuente, secciÃ³n (badge color), fecha, relevance_score, resumen si existe
- PaginaciÃ³n infinite scroll o botÃ³n "cargar mÃ¡s"

#### 3.3 â€” Sistema de Feedback (por SecciÃ³n)
- `POST /api/feedback` â€” registra like/dislike/save, vinculado a la secciÃ³n del artÃ­culo
- Cuando hay nuevo feedback, se recalcula el perfil **de la secciÃ³n correspondiente**:
  - `section_profiles.positive_embedding` = promedio de embeddings de artÃ­culos con like **en esa secciÃ³n**
  - `section_profiles.negative_embedding` = promedio de embeddings de artÃ­culos con dislike **en esa secciÃ³n**
  - Se usa media mÃ³vil exponencial para dar mÃ¡s peso a feedback reciente
- El recÃ¡lculo es un Job que corre tras cada feedback (o batched cada hora)
- **La UI muestra el efecto por secciÃ³n**: "ğŸ”’ Cyber: 23 likes, 5 dislikes | ğŸ’» Tech: 31 likes, 8 dislikes"
- **Cada secciÃ³n evoluciona independientemente**: dar like a noticias de NVIDIA en Economy no afecta al perfil de Cybersecurity

#### 3.4 â€” GestiÃ³n de Fuentes y Secciones
- PÃ¡gina de admin: ver todas las fuentes, su secciÃ³n(es), estado, Ãºltimo fetch, errores
- AÃ±adir nueva fuente RSS con URL y asignar a secciÃ³n(es)
- Habilitar/deshabilitar fuentes
- Habilitar/deshabilitar secciones completas
- Crear nueva secciÃ³n (nombre, icono, seed keywords, max artÃ­culos en briefing)
- Reordenar secciones en el briefing
- Ver estadÃ­sticas por fuente y por secciÃ³n: artÃ­culos ingestados, % que pasa el filtro

#### 3.5 â€” DiseÃ±o y UX
- Mobile-first (lo leerÃ¡s desde el mÃ³vil por la maÃ±ana)
- Tema oscuro por defecto (es una herramienta de maÃ±ana temprana)
- Minimalista â€” la informaciÃ³n es el protagonista, no la UI
- PWA bÃ¡sico: installable, funciona offline para leer el Ãºltimo briefing cacheado

### Criterio de Fase Completada
- Abres `flux.zyrak.cloud` por la maÃ±ana y lees el briefing del dÃ­a organizado en 4 secciones
- Puedes dar like/dislike a artÃ­culos y el feedback evoluciona por secciÃ³n
- Puedes navegar entre secciones (tabs/acordeones) y ver el feed filtrado por secciÃ³n
- Puedes aÃ±adir/quitar fuentes RSS y asignarlas a secciones desde la UI
- Puedes desactivar una secciÃ³n completa si no te interesa ese dÃ­a
- **Esto es el MVP funcional â€” a partir de aquÃ­, TODO es mejora incremental**

---

## FASE 4 â€” MÃ¡s Fuentes y DeduplicaciÃ³n Inteligente
**DuraciÃ³n estimada: 1.5 semanas**
**Objetivo: Reddit como fuente, GitHub Releases, y dedup semÃ¡ntica.**

### Tareas

#### 4.1 â€” Worker Reddit
- OAuth app (tipo "script", gratis para uso personal)
- Consulta `.json` de cada subreddit configurado (ej: `reddit.com/r/netsec/hot.json`)
- Para posts con score > threshold (configurable por subreddit):
  - Si es link post: descarga artÃ­culo externo con `go-readability`
  - Si es self post: guarda el texto del post
  - Guarda metadata: `{"reddit_score": 234, "reddit_comments": 45, "subreddit": "netsec"}`
- Respeta rate limits de Reddit (60 req/min con OAuth)
- CronJob: cada 30 minutos

#### 4.2 â€” Worker GitHub Releases
- El usuario configura repos a seguir (ej: `kubernetes/kubernetes`, `traefik/traefik`)
- Usa la API de GitHub (con token personal, 5000 req/h)
- Monitoriza nuevas releases: tag, nombre, release notes
- Guarda el changelog/release notes como contenido del artÃ­culo
- CronJob: cada 1 hora

#### 4.3 â€” DeduplicaciÃ³n SemÃ¡ntica
- Problema: la misma noticia aparece en HN, Reddit, y 3 feeds RSS con URLs diferentes
- SoluciÃ³n: tras calcular embedding, busca artÃ­culos de las Ãºltimas 48h con similaridad coseno > 0.85
- Si hay match, agrupa como "cluster" â€” guarda `cluster_id` en metadata
- En el briefing, se presentan como uno solo: "Reportado por: HN (142 pts), Reddit r/netsec (89 pts), BleepingComputer"
- Esto mejora drÃ¡sticamente la calidad del briefing â€” en vez de ver la misma noticia 4 veces, ves una sÃ­ntesis con mÃºltiples perspectivas

### Criterio de Fase Completada
- Reddit y GitHub Releases funcionan como fuentes
- ArtÃ­culos duplicados se agrupan automÃ¡ticamente
- El briefing muestra "visto en X fuentes" para noticias multi-fuente

---

## FASE 5 â€” BÃºsqueda SemÃ¡ntica y Archivo HistÃ³rico
**DuraciÃ³n estimada: 1.5 semanas**
**Objetivo: Poder preguntar "Â¿QuÃ© se dijo sobre X la semana pasada?" y obtener respuestas.**

### Tareas

#### 5.1 â€” Endpoint de BÃºsqueda SemÃ¡ntica
- `POST /api/search` con query en lenguaje natural
- Pipeline:
  1. Calcula embedding de la query
  2. Busca los 20 artÃ­culos mÃ¡s similares en pgvector (`ORDER BY embedding <=> query_embedding LIMIT 20`)
  3. Filtra por rango de fechas si se especifica
  4. Devuelve resultados con score de similaridad

#### 5.2 â€” BÃºsqueda Conversacional (RAG bÃ¡sico)
- `POST /api/ask` con pregunta en lenguaje natural
- Pipeline:
  1. BÃºsqueda semÃ¡ntica â†’ top 10 artÃ­culos relevantes
  2. Prompt a GLM: "BasÃ¡ndote SOLO en estos artÃ­culos, responde la pregunta: [pregunta]. Cita tus fuentes."
  3. Devuelve respuesta + artÃ­culos fuente
- **LimitaciÃ³n clara**: solo responde sobre artÃ­culos que el sistema ha ingestado. No inventa.

#### 5.3 â€” UI de BÃºsqueda
- Barra de bÃºsqueda en el header, siempre accesible
- Resultados en tiempo real (embeddings locales = rÃ¡pido)
- Modo "pregunta" vs modo "buscar artÃ­culos"
- El RAG solo se dispara cuando se escribe una pregunta (detectado por `?` o phrasing interrogativo)

#### 5.4 â€” Archivo y Almacenamiento a Largo Plazo
- Los artÃ­culos >30 dÃ­as se mueven de la tabla principal a `articles_archive` (misma estructura)
- Los embeddings se mantienen â€” la bÃºsqueda semÃ¡ntica funciona sobre todo el archivo
- El contenido completo (HTML original) se comprime y almacena en el PVC de 24TB
- Stats en la UI: "Tu archivo: 12,847 artÃ­culos desde [fecha], ocupando 2.3GB"

### Criterio de Fase Completada
- Puedes buscar "vulnerabilidad kubernetes RBAC" y encontrar artÃ­culos relevantes de hace semanas
- Puedes preguntar "Â¿QuÃ© pasÃ³ con la filtraciÃ³n de GLM 5?" y obtener una respuesta basada en tus artÃ­culos
- El archivo histÃ³rico funciona y crece sin problemas en el DAS

---

## FASE 6 â€” Story Threading ("Seguir un Tema")
**DuraciÃ³n estimada: 2 semanas**
**Objetivo: Seguir la evoluciÃ³n de una historia a lo largo de dÃ­as/semanas.**

### Tareas

#### 6.1 â€” Modelo de Stories
```sql
CREATE TABLE stories (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    title TEXT NOT NULL,              -- "FiltraciÃ³n de GLM 5"
    summary TEXT,                     -- Resumen evolutivo generado por GLM
    embedding vector(384),            -- Embedding del tema
    status TEXT DEFAULT 'active',     -- active, stale, closed
    created_at TIMESTAMPTZ DEFAULT NOW(),
    last_updated_at TIMESTAMPTZ,
    article_count INTEGER DEFAULT 0
);

CREATE TABLE story_articles (
    story_id UUID REFERENCES stories(id),
    article_id UUID REFERENCES articles(id),
    added_at TIMESTAMPTZ DEFAULT NOW(),
    PRIMARY KEY (story_id, article_id)
);
```

#### 6.2 â€” CreaciÃ³n Manual de Stories
- BotÃ³n "Seguir este tema" en cualquier artÃ­culo
- Se crea una story con el embedding del artÃ­culo como semilla
- Los nuevos artÃ­culos que ingresan se comparan contra stories activas
- Si similaridad > 0.75, se aÃ±aden automÃ¡ticamente a la story

#### 6.3 â€” DetecciÃ³n AutomÃ¡tica de Stories
- Clustering de artÃ­culos recientes (Ãºltimas 48h) por similaridad de embeddings
- Si un cluster tiene >3 artÃ­culos de >2 fuentes diferentes, es candidato a story
- GLM genera un tÃ­tulo y resumen para la story detectada
- Se sugiere al usuario: "Posible tema emergente: [tÃ­tulo]. Â¿Seguir?"

#### 6.4 â€” UI de Stories
- PÃ¡gina dedicada: lista de stories activas
- Cada story muestra: tÃ­tulo, resumen actualizado, timeline de artÃ­culos, fuentes involucradas
- El briefing matutino incluye secciÃ³n "Actualizaciones en tus temas seguidos"

#### 6.5 â€” Lifecycle de Stories
- Stories sin artÃ­culos nuevos en 7 dÃ­as â†’ status `stale` (se dejan de monitorizar activamente)
- Stories sin artÃ­culos en 30 dÃ­as â†’ status `closed`
- El usuario puede reactivar una story cerrada manualmente

### Criterio de Fase Completada
- Puedes darle "Seguir" a un artÃ­culo sobre GLM-5 y al dÃ­a siguiente aparecen automÃ¡ticamente los benchmarks filtrados
- El sistema detecta temas emergentes y te los sugiere
- El briefing matutino tiene una secciÃ³n de "tus temas" con actualizaciones

---

## FASE 7 â€” Threat Intelligence Integration
**DuraciÃ³n estimada: 2 semanas**
**Objetivo: Convertir Briefing en ThreatBrief â€” CVEs y advisories matcheados contra tu infra.**

### Tareas

#### 7.1 â€” Worker NVD/CVE
- API NVD 2.0 (gratuita con API key, 50 req/30s con key)
- Ingesta de nuevos CVEs publicados en las Ãºltimas 24h
- Parsea: ID, descripciÃ³n, CVSS score, CPE affected, referencias
- Guarda como artÃ­culos con `source_type = 'nvd'`

#### 7.2 â€” Inventario de Infraestructura
```sql
CREATE TABLE infrastructure (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    component_type TEXT NOT NULL,     -- 'container_image', 'helm_release', 'go_dependency'
    name TEXT NOT NULL,               -- 'nginx', 'traefik', 'k3s'
    version TEXT,                     -- '1.25.3'
    namespace TEXT,                   -- k8s namespace
    last_seen TIMESTAMPTZ,
    metadata JSONB                    -- Extra info segÃºn tipo
);
```
- **Scanner CronJob**: consulta la API de Kubernetes de tu cluster y rellena esta tabla automÃ¡ticamente
  - ImÃ¡genes de contenedores en uso (con versiones)
  - Helm releases instalados
  - VersiÃ³n de k3s
- Match automÃ¡tico: cuando entra un CVE que afecta a `nginx 1.24.x` y tÃº tienes `nginx:1.24.3`, se marca como `high_priority`

#### 7.3 â€” Briefing de Seguridad
- El briefing matutino gana una secciÃ³n nueva: "ğŸ”’ Seguridad de tu infraestructura"
- CVEs que afectan directamente a tu stack, ordenados por CVSS
- Advisories de vendors relevantes (Red Hat, Kubernetes, etc.)
- GLM genera recomendaciones de acciÃ³n: "Actualiza nginx a 1.25.4 que parchea CVE-XXXX"

### Criterio de Fase Completada
- El sistema conoce quÃ© software corres en tu cluster
- Los CVEs relevantes para tu infra aparecen destacados en el briefing
- Recibes alertas priorizadas cuando hay CVEs crÃ­ticos que te afectan

---

## FASE 8 â€” Notificaciones y DistribuciÃ³n
**DuraciÃ³n estimada: 1 semana**
**Objetivo: Que el briefing te llegue, no que tengas que ir a buscarlo.**

### Tareas

#### 8.1 â€” Notificaciones por Telegram
- Bot de Telegram que envÃ­a el briefing matutino en formato Markdown
- Alertas urgentes para CVEs de severidad Critical que afecten a tu infra
- Comandos bÃ¡sicos: `/briefing` (Ãºltimo briefing), `/search [query]`, `/sources` (estado de fuentes)

#### 8.2 â€” Email Digest (opcional)
- SMTP con template HTML limpio
- Resumen del briefing + links al dashboard para detalle

#### 8.3 â€” PWA Push Notifications
- Web Push API para notificaciones en el navegador/mÃ³vil
- Solo para alertas de seguridad urgentes â€” el briefing normal se lee en la web

### Criterio de Fase Completada
- A las 07:00 recibes un mensaje de Telegram con tu briefing
- Si hay un CVE crÃ­tico que te afecta, recibes alerta inmediata

---

## FASE 9 â€” Pulido, Helm Chart PÃºblico y DocumentaciÃ³n
**DuraciÃ³n estimada: 1.5 semanas**
**Objetivo: Que cualquiera pueda desplegar Briefing en su propio cluster.**

### Tareas

#### 9.1 â€” Helm Chart ProducciÃ³n
- `values.yaml` bien documentado con todos los valores configurables
- Soporte para bases de datos externas (si el usuario ya tiene PostgreSQL)
- Resource limits y requests ajustados para homelab (bajo consumo por defecto)
- Soporte multi-arch (amd64 + arm64) en todas las imÃ¡genes
- Health checks, readiness probes, liveness probes en todos los deployments
- PodDisruptionBudgets donde tenga sentido

#### 9.2 â€” Onboarding / Setup Wizard
- Primera vez que accedes a la web: wizard de configuraciÃ³n
  - Paso 1: Elegir proveedor LLM (GLM / OpenAI-compatible / Anthropic) y configurar API key
  - Paso 2: Activar/desactivar secciones (ğŸ”’ Cyber, ğŸ’» Tech, ğŸ“ˆ Economy, ğŸŒ World) y opcionalmente crear nuevas
  - Paso 3: Seleccionar fuentes de un catÃ¡logo predefinido por secciÃ³n (con presets recomendados)
  - Paso 4: Configurar horario del briefing
  - Paso 5 (opcional): Conectar Telegram para notificaciones

#### 9.3 â€” DocumentaciÃ³n
- README.md completo con screenshots
- GuÃ­a de instalaciÃ³n (Helm + Docker Compose como alternativa)
- GuÃ­a de configuraciÃ³n de fuentes
- GuÃ­a de desarrollo para contribuidores
- Arquitectura documentada con diagramas

#### 9.4 â€” Observabilidad
- MÃ©tricas Prometheus expuestas por cada servicio
- Dashboard Grafana preconfigurado (como ConfigMap en Helm)
  - ArtÃ­culos ingestados/hora por fuente
  - Tasa de relevancia (% que pasa el filtro)
  - Uso de GLM (tokens estimados por briefing)
  - Estado de salud de las fuentes
  - Latencia del pipeline

### Criterio de Fase Completada
- `helm install flux oci://ghcr.io/zyrak/flux` funciona en un cluster limpio
- `docker compose up -d` funciona en cualquier mÃ¡quina con Docker
- Un usuario nuevo puede tener el sistema funcionando en <15 minutos (con cualquiera de los dos mÃ©todos)
- El README tiene screenshots y documentaciÃ³n clara
- Tu Grafana muestra el dashboard de Flux junto a tus dashboards existentes

---

## Resumen de Fases

| Fase | Nombre | DuraciÃ³n | Lo que obtienes |
|---|---|---|---|
| 0 | Scaffolding + LLM Abstraction + Rate Limiter | 1.5 semanas | Repo, Helm + Docker Compose, DB, CI, interfaz LLM abstracta, rate limiter |
| 1 | Ingesta RSS + HN | 1.5â€“2 sem | ArtÃ­culos fluyendo a la DB con rate limiting |
| 2 | Procesamiento LLM | 2 semanas | Briefing diario generado automÃ¡ticamente |
| 3 | Frontend + Feedback | 2 semanas | **MVP funcional â€” usable a diario** |
| 4 | Reddit + GitHub + Dedup | 1.5 sem | MÃ¡s fuentes, sin duplicados |
| 5 | BÃºsqueda SemÃ¡ntica | 1.5 sem | "Â¿QuÃ© pasÃ³ con X?" respondido |
| 6 | Story Threading | 2 semanas | Seguir la evoluciÃ³n de temas |
| 7 | Threat Intelligence | 2 semanas | CVEs matcheados contra tu infra |
| 8 | Notificaciones | 1 semana | Telegram + alertas |
| 9 | ProducciÃ³n + Docs | 1.5 sem | Helm chart + Docker Compose pÃºblico, onboarding |
| **Total** | | **~17 semanas** | **Plataforma completa** |

---

## Notas de Viabilidad y Riesgos

### Riesgo: Cambios en APIs externas
- Reddit ha restringido su API en 2023 pero el tier gratuito con OAuth sigue funcionando para uso personal
- HN usa Firebase y nunca ha cambiado su API en 10+ aÃ±os
- NVD API 2.0 es un servicio gubernamental estable
- **MitigaciÃ³n**: Cada worker es independiente. Si Reddit cierra su API maÃ±ana, pierdes una fuente pero el sistema sigue vivo.

### Riesgo: Cambios en el proveedor LLM
- GLM puede cambiar el plan Coding Lite, subir precios, o limitar el uso vÃ­a API
- **MitigaciÃ³n**: La interfaz abstracta `internal/llm.Analyzer` permite cambiar de backend en minutos. Si GLM deja de funcionar, configuras Ollama local, OpenAI, o Anthropic sin tocar una lÃ­nea de lÃ³gica de negocio.

### Riesgo: Baneo por exceso de requests
- Reddit, blogs individuales, y APIs pueden banear IPs que hacen demasiadas requests
- `go-readability` descargando contenido completo puede triggear protecciÃ³n anti-bot en algunos sitios
- **MitigaciÃ³n**: El rate limiter centralizado en `internal/ratelimit/` con Redis controla todas las requests salientes. Jitter aleatorio, respeto de `Retry-After`, backoff exponencial, y User-Agent identificativo reducen el riesgo a mÃ­nimos.

### Riesgo: Calidad del filtrado en cold start
- Sin feedback, el sistema depende de las seed keywords para el perfil inicial
- Los primeros 3-5 dÃ­as el briefing serÃ¡ imperfecto
- **MitigaciÃ³n**: Hacer el threshold de relevancia mÃ¡s permisivo los primeros 7 dÃ­as. Mejor mostrar algo de ruido que perder seÃ±al.

### Riesgo: Capacidad de GLM en el cap de 5h
- Con el plan Coding Lite, no hay lÃ­mite de tokens explÃ­cito sino un "cap" por ventana de 5h
- Si procesas ~200 artÃ­culos con clasificaciÃ³n + ~30 con resumen + 1 briefing completo, es un volumen moderado
- **MitigaciÃ³n**: El filtrado por embeddings (gratuito, local) reduce drÃ¡sticamente lo que llega a GLM. Monitoriza el uso y ajusta el threshold si te acercas al lÃ­mite.

### Riesgo: Complejidad acumulada
- 17 semanas es optimista si trabajas solo en tiempo libre â€” cuenta con 5-6 meses realistas para el MVP (fases 0-3) y 9-12 meses para el proyecto completo
- **MitigaciÃ³n**: Las fases 0-3 son el MVP. Si solo llegas ahÃ­, ya tienes un producto Ãºtil. Todo lo demÃ¡s es mejora incremental. No intentes construir la fase 7 sin haber usado la fase 3 durante al menos dos semanas.
